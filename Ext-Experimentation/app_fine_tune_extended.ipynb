{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extended Subproject - Fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.optim import AdamW  # Import PyTorch's AdamW\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import BertTokenizer, BertForTokenClassification , AdamW, BertTokenizerFast\n",
    "#from transformers import LongformerTokenizer, LongformerForSequenceClassification, AdamW\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasets\n",
    "train_data = pd.read_csv(\"cnndm/train_data_ext.csv\", sep=';')\n",
    "valid_data = pd.read_csv(\"cnndm/valid_data_ext.csv\", sep=';')\n",
    "test_data = pd.read_csv(\"cnndm/test_data_ext.csv\", sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0    0\n",
      "article       0\n",
      "highlights    0\n",
      "label         0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>article</th>\n",
       "      <th>highlights</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>LONDON, England (Reuters) -- Harry Potter star...</td>\n",
       "      <td>Harry Potter star Daniel Radcliffe gets £20M f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Editor's note: In our Behind the Scenes series...</td>\n",
       "      <td>Mentally ill inmates in Miami are housed on th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>MINNEAPOLIS, Minnesota (CNN) -- Drivers who we...</td>\n",
       "      <td>NEW: \"I thought I was going to die,\" driver sa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>WASHINGTON (CNN) -- Doctors removed five small...</td>\n",
       "      <td>Five small polyps found during procedure; \"non...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>(CNN)  -- The National Football League has ind...</td>\n",
       "      <td>NEW: NFL chief, Atlanta Falcons owner critical...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                            article  \\\n",
       "0           1  LONDON, England (Reuters) -- Harry Potter star...   \n",
       "1           2  Editor's note: In our Behind the Scenes series...   \n",
       "2           3  MINNEAPOLIS, Minnesota (CNN) -- Drivers who we...   \n",
       "3           4  WASHINGTON (CNN) -- Doctors removed five small...   \n",
       "4           5  (CNN)  -- The National Football League has ind...   \n",
       "\n",
       "                                          highlights  label  \n",
       "0  Harry Potter star Daniel Radcliffe gets £20M f...      0  \n",
       "1  Mentally ill inmates in Miami are housed on th...      0  \n",
       "2  NEW: \"I thought I was going to die,\" driver sa...      0  \n",
       "3  Five small polyps found during procedure; \"non...      0  \n",
       "4  NEW: NFL chief, Atlanta Falcons owner critical...      0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train_data.isna().sum())\n",
    "missing_rows = train_data[train_data.isna().any(axis=1)]\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>article</th>\n",
       "      <th>highlights</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13789</th>\n",
       "      <td>69951</td>\n",
       "      <td>ATLANTA, Georgia (CNN) -- Shoes tell a lot abo...</td>\n",
       "      <td>Some people get [B-hallucinated] rare diseases...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13790</th>\n",
       "      <td>69971</td>\n",
       "      <td>ATLANTA, Georgia (CNN) --   An advisory panel ...</td>\n",
       "      <td>Panel recommends health care workers wear [B-h...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13791</th>\n",
       "      <td>69981</td>\n",
       "      <td>Washington (CNN) -- President Obama toasted a ...</td>\n",
       "      <td>NEW: [B-hallucinated]Obama unexpectedly breaks...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13792</th>\n",
       "      <td>69991</td>\n",
       "      <td>Editor's note: Tananarive Due is an American B...</td>\n",
       "      <td>Tananarive Due: [B-hallucinated]admits her fam...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13793</th>\n",
       "      <td>70001</td>\n",
       "      <td>(CNN) -- Health officials say the H1N1 virus, ...</td>\n",
       "      <td>CDC reported higher levels of flu activity tha...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                            article  \\\n",
       "13789       69951  ATLANTA, Georgia (CNN) -- Shoes tell a lot abo...   \n",
       "13790       69971  ATLANTA, Georgia (CNN) --   An advisory panel ...   \n",
       "13791       69981  Washington (CNN) -- President Obama toasted a ...   \n",
       "13792       69991  Editor's note: Tananarive Due is an American B...   \n",
       "13793       70001  (CNN) -- Health officials say the H1N1 virus, ...   \n",
       "\n",
       "                                              highlights  label  \n",
       "13789  Some people get [B-hallucinated] rare diseases...      1  \n",
       "13790  Panel recommends health care workers wear [B-h...      1  \n",
       "13791  NEW: [B-hallucinated]Obama unexpectedly breaks...      1  \n",
       "13792  Tananarive Due: [B-hallucinated]admits her fam...      1  \n",
       "13793  CDC reported higher levels of flu activity tha...      1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model and Tokenizer Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load the tokenizer and model\n",
    "tokenizer = BertTokenizerFast.from_pretrained(\"prajjwal1/bert-tiny\")\n",
    "model = BertForTokenClassification.from_pretrained(\"prajjwal1/bert-tiny\", num_labels=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data for Fine-Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenLevelDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer, max_length=512):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.examples = []\n",
    "        self.skipped_count = 0  # Counter for rows skipped due to document length\n",
    "        self.skipped_bc_chunk = 0  # Counter for rows skipped due to chunking issues\n",
    "\n",
    "        self._create_examples()\n",
    "\n",
    "    def _create_examples(self):\n",
    "        for _, row in self.data.iterrows():\n",
    "            doc = row['article']\n",
    "            summ = row['highlights']\n",
    "\n",
    "            # Replace [B-hallucinated] and [E-hallucinated] with markers\n",
    "            summ = summ.replace(\"[B-hallucinated]\", \" B_hall \").replace(\"[E-hallucinated]\", \" E_hall \")\n",
    "\n",
    "            # Tokenize the document with offsets\n",
    "            doc_tokenized = self.tokenizer(doc, padding=False, truncation=False)\n",
    "            doc_tokens = doc_tokenized[\"input_ids\"]\n",
    "\n",
    "            # Tokenize the summary with offsets\n",
    "            summ_tokenized = self.tokenizer(\n",
    "                summ, padding=False, truncation=False, return_offsets_mapping=True\n",
    "            )\n",
    "            summ_tokens = summ_tokenized[\"input_ids\"]\n",
    "            summ_offsets = summ_tokenized[\"offset_mapping\"]\n",
    "\n",
    "            if len(doc_tokens) + 3 > self.max_length:  # Check if document alone exceeds the max length\n",
    "                self.skipped_count += 1\n",
    "                continue\n",
    "\n",
    "            # Helper function to check if a chunk fits within max_length\n",
    "            def chunk_fits(tokens_chunk):\n",
    "                return len(doc_tokens) + len(tokens_chunk) + 3 <= self.max_length\n",
    "\n",
    "            # Case 1: Full summary fits\n",
    "            if chunk_fits(summ_tokens):\n",
    "                self._add_example(doc_tokens, summ_tokens, summ_offsets)\n",
    "            else:\n",
    "                # Case 2: Try splitting into halves\n",
    "                mid = len(summ_tokens) // 2\n",
    "                if chunk_fits(summ_tokens[:mid]) and chunk_fits(summ_tokens[mid:]):\n",
    "                    for chunk, offsets in zip([summ_tokens[:mid], summ_tokens[mid:]],\n",
    "                                            [summ_offsets[:mid], summ_offsets[mid:]]):\n",
    "                        self._add_example(doc_tokens, chunk, offsets)\n",
    "                else:\n",
    "                    # Case 3: Try splitting into thirds\n",
    "                    third = len(summ_tokens) // 3\n",
    "                    chunks = [summ_tokens[:third], summ_tokens[third:2 * third], summ_tokens[2 * third:]]\n",
    "                    offsets_chunks = [\n",
    "                        summ_offsets[:third],\n",
    "                        summ_offsets[third:2 * third],\n",
    "                        summ_offsets[2 * third:]\n",
    "                    ]\n",
    "                    if all(chunk_fits(chunk) for chunk in chunks):\n",
    "                        for chunk, offsets in zip(chunks, offsets_chunks):\n",
    "                            self._add_example(doc_tokens, chunk, offsets)\n",
    "                    else:\n",
    "                        # Case 4: Skip if none of the strategies work\n",
    "                        self.skipped_bc_chunk += 1\n",
    "\n",
    "    def _add_example(self, doc_tokens, summ_tokens, summ_offsets):\n",
    "        input_ids = [self.tokenizer.cls_token_id] + doc_tokens + \\\n",
    "                    [self.tokenizer.sep_token_id] + summ_tokens + \\\n",
    "                    [self.tokenizer.sep_token_id]\n",
    "\n",
    "        attention_mask = [1] * len(input_ids)\n",
    "\n",
    "        # Generate token-level labels\n",
    "        token_labels = [0] * len(input_ids)  # Initialize all labels as 0\n",
    "        for idx, (start, end) in enumerate(summ_offsets):\n",
    "            if start == 0 and end == 0:  # Skip special tokens\n",
    "                continue\n",
    "            token_text = self.tokenizer.convert_ids_to_tokens([summ_tokens[idx]])[0]\n",
    "            if token_text in [\"B_hall\", \"E_hall\"]:\n",
    "                token_labels[idx + len(doc_tokens) + 2] = 1  # Adjust index for document and special tokens\n",
    "\n",
    "        # Pad if necessary\n",
    "        if len(input_ids) < self.max_length:\n",
    "            pad_length = self.max_length - len(input_ids)\n",
    "            input_ids += [self.tokenizer.pad_token_id] * pad_length\n",
    "            attention_mask += [0] * pad_length\n",
    "            token_labels += [-100] * pad_length  # Ignore padded positions in loss computation\n",
    "\n",
    "        self.examples.append({\n",
    "            \"input_ids\": input_ids,\n",
    "            \"attention_mask\": attention_mask,\n",
    "            \"token_labels\": token_labels\n",
    "        })\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.examples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        example = self.examples[idx]\n",
    "        return {\n",
    "            \"input_ids\": torch.tensor(example[\"input_ids\"], dtype=torch.long),\n",
    "            \"attention_mask\": torch.tensor(example[\"attention_mask\"], dtype=torch.long),\n",
    "            \"token_labels\": torch.tensor(example[\"token_labels\"], dtype=torch.long)\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "MAX_LEN = 512 # 2048 # das setzen wir als balance zwischen wie viele padding brauchen und wie viele rausfallen\n",
    "\n",
    "# Prepare datasets\n",
    "train_dataset = TokenLevelDataset(train_data, tokenizer, max_length=MAX_LEN)\n",
    "valid_dataset = TokenLevelDataset(valid_data, tokenizer, max_length=MAX_LEN)\n",
    "test_dataset = TokenLevelDataset(test_data, tokenizer, max_length=MAX_LEN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 10082/13794 ~ 73.08974916630419 %\n",
      "Test: 1350/1974 ~ 68.38905775075987 %\n",
      "Valid: 1412/1966 ~ 71.82095625635809 %\n"
     ]
    }
   ],
   "source": [
    "print(f'Train: {train_dataset.skipped_count}/{train_data.shape[0]} ~ {train_dataset.skipped_count/train_data.shape[0] * 100} %')\n",
    "print(f'Test: {test_dataset.skipped_count}/{test_data.shape[0]} ~ {test_dataset.skipped_count/test_data.shape[0] * 100} %')\n",
    "print(f'Valid: {valid_dataset.skipped_count}/{valid_data.shape[0]} ~ {valid_dataset.skipped_count/valid_data.shape[0] * 100} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 383/13794 ~ 2.7765695229810063 %\n",
      "Test: 42/1974 ~ 2.127659574468085 %\n",
      "Valid: 40/1966 ~ 2.034587995930824 %\n"
     ]
    }
   ],
   "source": [
    "print(f'Train: {train_dataset.skipped_bc_chunk}/{train_data.shape[0]} ~ {train_dataset.skipped_bc_chunk/train_data.shape[0] * 100} %')\n",
    "print(f'Test: {test_dataset.skipped_bc_chunk}/{test_data.shape[0]} ~ {test_dataset.skipped_bc_chunk/test_data.shape[0] * 100} %')\n",
    "print(f'Valid: {valid_dataset.skipped_bc_chunk}/{valid_data.shape[0]} ~ {valid_dataset.skipped_bc_chunk/valid_data.shape[0] * 100} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Mocca\\anaconda3\\envs\\adl_project\\lib\\site-packages\\transformers\\optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 16\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "# Device setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "print(device)\n",
    "\n",
    "# Loss function\n",
    "criterion = torch.nn.CrossEntropyLoss(ignore_index=-100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, data_loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "    total_tokens = 0\n",
    "\n",
    "    for batch in data_loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        token_labels = batch['token_labels'].to(device)\n",
    "\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits  # Shape: (batch_size, seq_len, num_labels)\n",
    "\n",
    "        # Flatten logits and labels for loss computation\n",
    "        logits = logits.view(-1, logits.shape[-1])  # Shape: (batch_size * seq_len, num_labels)\n",
    "        labels = token_labels.view(-1)  # Shape: (batch_size * seq_len)\n",
    "\n",
    "        # Debugging: print shapes\n",
    "        #print(f\"Logits shape: {logits.shape}, Labels shape: {labels.shape}\")\n",
    "\n",
    "        # Compute loss\n",
    "        loss = criterion(logits, labels)\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        # Predictions\n",
    "        preds = torch.argmax(logits, dim=1)  # Shape: (batch_size * seq_len)\n",
    "        mask = labels != -100  # Ignore padded labels\n",
    "        correct_predictions += torch.sum((preds == labels) & mask)\n",
    "        total_tokens += torch.sum(mask)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    # Avoid division by zero\n",
    "    if total_tokens == 0:\n",
    "        raise ValueError(\"Total tokens processed is zero. Check your token labels or dataset.\")\n",
    "\n",
    "    accuracy = correct_predictions.double() / total_tokens\n",
    "    return accuracy, sum(losses) / len(losses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model, data_loader, criterion, device):\n",
    "    model.eval()\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "    total_tokens = 0\n",
    "\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            token_labels = batch['token_labels'].to(device)\n",
    "\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits  # Shape: (batch_size, seq_len, num_labels)\n",
    "\n",
    "            # Flatten logits and labels for loss computation\n",
    "            logits = logits.view(-1, logits.shape[-1])  # Shape: (batch_size * seq_len, num_labels)\n",
    "            labels = token_labels.view(-1)  # Shape: (batch_size * seq_len)\n",
    "\n",
    "            # Compute loss\n",
    "            loss = criterion(logits, labels)\n",
    "            losses.append(loss.item())\n",
    "\n",
    "            # Predictions\n",
    "            preds = torch.argmax(logits, dim=1)  # Shape: (batch_size * seq_len)\n",
    "            mask = labels != -100  # Ignore padded labels\n",
    "            correct_predictions += torch.sum((preds == labels) & mask)\n",
    "            total_tokens += torch.sum(mask)\n",
    "\n",
    "            # Collect predictions and labels for evaluation metrics\n",
    "            all_preds.extend(preds[mask].cpu().numpy())\n",
    "            all_labels.extend(labels[mask].cpu().numpy())\n",
    "\n",
    "    accuracy = correct_predictions.double() / total_tokens\n",
    "\n",
    "    return accuracy, sum(losses) / len(losses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "----------\n",
      "Train Loss: 0.0057, Train Token Accuracy: 1.0000\n",
      "Validation Loss: 0.0038, Validation Token Accuracy: 1.0000\n",
      "Validation performance improved. Model saved.\n",
      "Epoch 2/20\n",
      "----------\n",
      "Train Loss: 0.0043, Train Token Accuracy: 1.0000\n",
      "Validation Loss: 0.0029, Validation Token Accuracy: 1.0000\n",
      "Validation performance improved. Model saved.\n",
      "Epoch 3/20\n",
      "----------\n",
      "Train Loss: 0.0034, Train Token Accuracy: 1.0000\n",
      "Validation Loss: 0.0023, Validation Token Accuracy: 1.0000\n",
      "Validation performance improved. Model saved.\n",
      "Epoch 4/20\n",
      "----------\n",
      "Train Loss: 0.0026, Train Token Accuracy: 1.0000\n",
      "Validation Loss: 0.0018, Validation Token Accuracy: 1.0000\n",
      "Validation performance improved. Model saved.\n",
      "Epoch 5/20\n",
      "----------\n",
      "Train Loss: 0.0021, Train Token Accuracy: 1.0000\n",
      "Validation Loss: 0.0014, Validation Token Accuracy: 1.0000\n",
      "Validation performance improved. Model saved.\n",
      "Epoch 6/20\n",
      "----------\n",
      "Train Loss: 0.0017, Train Token Accuracy: 1.0000\n",
      "Validation Loss: 0.0012, Validation Token Accuracy: 1.0000\n",
      "Validation performance improved. Model saved.\n",
      "Epoch 7/20\n",
      "----------\n",
      "Train Loss: 0.0014, Train Token Accuracy: 1.0000\n",
      "Validation Loss: 0.0009, Validation Token Accuracy: 1.0000\n",
      "Validation performance improved. Model saved.\n",
      "Epoch 8/20\n",
      "----------\n",
      "Train Loss: 0.0012, Train Token Accuracy: 1.0000\n",
      "Validation Loss: 0.0008, Validation Token Accuracy: 1.0000\n",
      "Validation performance improved. Model saved.\n",
      "Epoch 9/20\n",
      "----------\n",
      "Train Loss: 0.0010, Train Token Accuracy: 1.0000\n",
      "Validation Loss: 0.0006, Validation Token Accuracy: 1.0000\n",
      "Validation performance improved. Model saved.\n",
      "Epoch 10/20\n",
      "----------\n",
      "Train Loss: 0.0008, Train Token Accuracy: 1.0000\n",
      "Validation Loss: 0.0005, Validation Token Accuracy: 1.0000\n",
      "Validation performance improved. Model saved.\n",
      "Epoch 11/20\n",
      "----------\n",
      "Train Loss: 0.0007, Train Token Accuracy: 1.0000\n",
      "Validation Loss: 0.0004, Validation Token Accuracy: 1.0000\n",
      "Validation performance improved. Model saved.\n",
      "Epoch 12/20\n",
      "----------\n",
      "Train Loss: 0.0006, Train Token Accuracy: 1.0000\n",
      "Validation Loss: 0.0004, Validation Token Accuracy: 1.0000\n",
      "Validation performance improved. Model saved.\n",
      "Epoch 13/20\n",
      "----------\n",
      "Train Loss: 0.0005, Train Token Accuracy: 1.0000\n",
      "Validation Loss: 0.0003, Validation Token Accuracy: 1.0000\n",
      "Validation performance improved. Model saved.\n",
      "Epoch 14/20\n",
      "----------\n",
      "Train Loss: 0.0004, Train Token Accuracy: 1.0000\n",
      "Validation Loss: 0.0003, Validation Token Accuracy: 1.0000\n",
      "Validation performance improved. Model saved.\n",
      "Epoch 15/20\n",
      "----------\n",
      "Train Loss: 0.0003, Train Token Accuracy: 1.0000\n",
      "Validation Loss: 0.0002, Validation Token Accuracy: 1.0000\n",
      "Validation performance improved. Model saved.\n",
      "Epoch 16/20\n",
      "----------\n",
      "Train Loss: 0.0003, Train Token Accuracy: 1.0000\n",
      "Validation Loss: 0.0002, Validation Token Accuracy: 1.0000\n",
      "Validation performance improved. Model saved.\n",
      "Epoch 17/20\n",
      "----------\n",
      "Train Loss: 0.0003, Train Token Accuracy: 1.0000\n",
      "Validation Loss: 0.0002, Validation Token Accuracy: 1.0000\n",
      "Validation performance improved. Model saved.\n",
      "Epoch 18/20\n",
      "----------\n",
      "Train Loss: 0.0002, Train Token Accuracy: 1.0000\n",
      "Validation Loss: 0.0001, Validation Token Accuracy: 1.0000\n",
      "Validation performance improved. Model saved.\n",
      "Epoch 19/20\n",
      "----------\n",
      "Train Loss: 0.0002, Train Token Accuracy: 1.0000\n",
      "Validation Loss: 0.0001, Validation Token Accuracy: 1.0000\n",
      "Validation performance improved. Model saved.\n",
      "Epoch 20/20\n",
      "----------\n",
      "Train Loss: 0.0002, Train Token Accuracy: 1.0000\n",
      "Validation Loss: 0.0001, Validation Token Accuracy: 1.0000\n",
      "Validation performance improved. Model saved.\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 20  # Maximum number of epochs\n",
    "PATIENCE = 5  # Number of epochs to wait for improvement\n",
    "best_val_loss = float('inf')  # Initialize with a large value\n",
    "early_stopping_counter = 0  # Tracks epochs without improvement\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"Epoch {epoch + 1}/{EPOCHS}\")\n",
    "    print(\"-\" * 10)\n",
    "\n",
    "    # Train for one epoch\n",
    "    train_acc, train_loss = train_epoch(model, train_loader, optimizer, criterion, device)\n",
    "    print(f\"Train Loss: {train_loss:.4f}, Train Token Accuracy: {train_acc:.4f}\")\n",
    "\n",
    "    # Evaluate on validation set\n",
    "    val_acc, val_loss = eval_model(model, valid_loader, criterion, device)\n",
    "    print(f\"Validation Loss: {val_loss:.4f}, Validation Token Accuracy: {val_acc:.4f}\")\n",
    "\n",
    "    # Check for improvement\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        early_stopping_counter = 0  # Reset counter if performance improves\n",
    "        torch.save(model.state_dict(), 'models/best_model_state_token.bin')  # Save the best model\n",
    "        print(\"Validation performance improved. Model saved.\")\n",
    "    else:\n",
    "        early_stopping_counter += 1  # Increment counter if no improvement\n",
    "        print(f\"No improvement. Early stopping counter: {early_stopping_counter}/{PATIENCE}\")\n",
    "\n",
    "    # Stop training if early stopping criteria are met\n",
    "    if early_stopping_counter >= PATIENCE:\n",
    "        print(\"Early stopping triggered. Training stopped.\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mocca\\AppData\\Local\\Temp\\ipykernel_23260\\4261843030.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('models/best_model_state_token.bin'))\n",
      "C:\\Users\\Mocca\\AppData\\Local\\Temp\\ipykernel_23260\\4261843030.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('models/best_model_state_token.bin'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.00010145309158057595 | Test accuracy: 1.0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Number of classes, 1, does not match size of target_names, 2. Try specifying the labels parameter",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 42\u001b[0m\n\u001b[0;32m     39\u001b[0m         all_labels\u001b[38;5;241m.\u001b[39mextend(valid_labels)\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# Generate a classification report\u001b[39;00m\n\u001b[1;32m---> 42\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mclassification_report\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_preds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mNon-Hallucinated\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mHallucinated\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\Mocca\\anaconda3\\envs\\adl_project\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:216\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    212\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    213\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    214\u001b[0m         )\n\u001b[0;32m    215\u001b[0m     ):\n\u001b[1;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    222\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    223\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    224\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    225\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    226\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Mocca\\anaconda3\\envs\\adl_project\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2693\u001b[0m, in \u001b[0;36mclassification_report\u001b[1;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[0;32m   2687\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   2688\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels size, \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m, does not match size of target_names, \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   2689\u001b[0m                 \u001b[38;5;28mlen\u001b[39m(labels), \u001b[38;5;28mlen\u001b[39m(target_names)\n\u001b[0;32m   2690\u001b[0m             )\n\u001b[0;32m   2691\u001b[0m         )\n\u001b[0;32m   2692\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2693\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2694\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of classes, \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m, does not match size of \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2695\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget_names, \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m. Try specifying the labels \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2696\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mlen\u001b[39m(labels), \u001b[38;5;28mlen\u001b[39m(target_names))\n\u001b[0;32m   2697\u001b[0m         )\n\u001b[0;32m   2698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m target_names \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2699\u001b[0m     target_names \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m l \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m labels]\n",
      "\u001b[1;31mValueError\u001b[0m: Number of classes, 1, does not match size of target_names, 2. Try specifying the labels parameter"
     ]
    }
   ],
   "source": [
    "# Load the best model for evaluation on the test set\n",
    "model.load_state_dict(torch.load('models/best_model_state_token.bin'))\n",
    "# Load the best model for evaluation on the test set\n",
    "model.load_state_dict(torch.load('models/best_model_state_token.bin'))\n",
    "\n",
    "test_acc, test_loss = eval_model(model, test_loader, criterion, device)\n",
    "print(f'Test loss: {test_loss} | Test accuracy: {test_acc}')\n",
    "\n",
    "# Initialize lists for predictions and true labels\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        # Move inputs and labels to the device\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        token_labels = batch['token_labels'].to(device)  # Token-level labels\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits  # Shape: (batch_size, seq_len, num_labels)\n",
    "\n",
    "        # Get predictions and flatten them\n",
    "        preds = torch.argmax(logits, dim=-1)  # Shape: (batch_size, seq_len)\n",
    "        flattened_preds = preds.view(-1).cpu().numpy()\n",
    "\n",
    "        # Flatten labels and apply the attention mask\n",
    "        flattened_labels = token_labels.view(-1).cpu().numpy()\n",
    "        attention_mask_flat = attention_mask.view(-1).cpu().numpy()\n",
    "\n",
    "        # Mask predictions and labels to exclude padding (-100)\n",
    "        valid_preds = flattened_preds[flattened_labels != -100]\n",
    "        valid_labels = flattened_labels[flattened_labels != -100]\n",
    "\n",
    "        # Append valid predictions and labels for metrics\n",
    "        all_preds.extend(valid_preds)\n",
    "        all_labels.extend(valid_labels)\n",
    "\n",
    "# Generate a classification report\n",
    "print(classification_report(all_labels, all_preds, target_names=[\"Non-Hallucinated\", \"Hallucinated\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adl_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
