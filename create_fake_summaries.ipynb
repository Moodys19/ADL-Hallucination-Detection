{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Hallucinated Summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# from folder functions\n",
    "from functions.load_subsampled_data import load_first_n_rows\n",
    "from functions.call_llama import generate_chat_completion, create_hallucinated_summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subsample files for train with 7000 rows already exist. Loading them.\n"
     ]
    }
   ],
   "source": [
    "# load subsample data\n",
    "file_paths_train = {\n",
    "    \"train\": {\"src\": \"cnndm/train.src\", \"tgt\": \"cnndm/train.tgt\"}\n",
    "}\n",
    "\n",
    "datasets_train = load_first_n_rows(7000, file_paths=file_paths_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subsample files for train with 5 rows already exist. Loading them.\n"
     ]
    }
   ],
   "source": [
    "datasets_train_5 = load_first_n_rows(5, file_paths=file_paths_train) # used for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subsample files for test with 1000 rows already exist. Loading them.\n",
      "Subsample files for valid with 1000 rows already exist. Loading them.\n"
     ]
    }
   ],
   "source": [
    "# load subsample data\n",
    "file_paths_test_val = {\n",
    "    \"test\": {\"src\": \"cnndm/test.src\", \"tgt\": \"cnndm/test.tgt\"},\n",
    "    \"valid\": {\"src\": \"cnndm/valid.src\", \"tgt\": \"cnndm/valid.tgt\"}\n",
    "}\n",
    "\n",
    "datasets_test_val = load_first_n_rows(1000, file_paths=file_paths_test_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              source  \\\n",
      "0  Editor's note: In our Behind the Scenes series...   \n",
      "1  LONDON, England (Reuters) -- Harry Potter star...   \n",
      "2  MINNEAPOLIS, Minnesota (CNN) -- Drivers who we...   \n",
      "3  BAGHDAD, Iraq (CNN) -- Dressed in a Superman s...   \n",
      "4  WASHINGTON (CNN) -- Doctors removed five small...   \n",
      "\n",
      "                                              target  \n",
      "0  Mentally ill inmates in Miami are housed on th...  \n",
      "1  Harry Potter star Daniel Radcliffe gets Â£20M f...  \n",
      "2  NEW: \"I thought I was going to die,\" driver sa...  \n",
      "3  Parents beam with pride, can't stop from smili...  \n",
      "4  Five small polyps found during procedure; \"non...  \n",
      "                                              source  \\\n",
      "0  Marseille, France (CNN)The French prosecutor l...   \n",
      "1  The Palestinian Authority officially became th...   \n",
      "2  Governments around the world are using the thr...   \n",
      "3  On May 28, 2014, some 7,000 people gathered in...   \n",
      "4  Seventy years ago, Anne Frank died of typhus i...   \n",
      "\n",
      "                                              target  \n",
      "0  Marseille prosecutor says \"so far no videos we...  \n",
      "1  Membership gives the ICC jurisdiction over all...  \n",
      "2  Amnesty's annual death penalty report catalogs...  \n",
      "3  Amnesty International releases its annual revi...  \n",
      "4  Museum: Anne Frank died earlier than previousl...  \n",
      "                                              source  \\\n",
      "0  The only thing crazier than a guy in snowbound...   \n",
      "1  On the 6th of April 1996, San Jose Clash and D...   \n",
      "2  French striker Bafetimbi Gomis, who has a hist...   \n",
      "3  My vote for Father of the Year goes to Curt Sc...   \n",
      "4  It was an act of frustration perhaps more comm...   \n",
      "\n",
      "                                              target  \n",
      "0  A man in suburban Boston is selling snow onlin...  \n",
      "1  The 20th MLS season begins this weekend. Leagu...  \n",
      "2  Bafetimbi Gomis collapses within 10 minutes of...  \n",
      "3  Ruben Navarrette: Schilling deserves praise fo...  \n",
      "4  Rory McIlroy throws club into water at WGC Cad...  \n"
     ]
    }
   ],
   "source": [
    "print(datasets_train[\"train\"].head())\n",
    "print(datasets_test_val[\"test\"].head())\n",
    "print(datasets_test_val[\"valid\"].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    696\n",
       "1    453\n",
       "2    739\n",
       "3    704\n",
       "4    412\n",
       "Name: source, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate word count for each column in the DataFrame\n",
    "source_word_count = datasets_train[\"train\"][\"source\"].apply(lambda x: len(str(x).split()))\n",
    "target_word_count = datasets_train[\"train\"][\"target\"].apply(lambda x: len(str(x).split()))\n",
    "\n",
    "source_word_count.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40.778285714285715\n",
      "71\n",
      "616.3961428571429\n"
     ]
    }
   ],
   "source": [
    "print(target_word_count.mean())\n",
    "print(target_word_count.max())\n",
    "print(source_word_count.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Train Set Hallucinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path check\n",
      "Processing 5/5 rows...\n",
      "Progress saved to cnndm/fake_summary/check_function.csv after 5 rows.\n",
      "\n",
      "Processing complete!\n"
     ]
    }
   ],
   "source": [
    "bad_path = \"test_case\"\n",
    "good_path = \"cnndm/fake_summary/check_function.csv\"\n",
    "\n",
    "fake_train_5 = create_hallucinated_summaries(\n",
    "    df=datasets_train_5[\"train\"], \n",
    "    source_col=\"source\", \n",
    "    target_col=\"target\",\n",
    "    output_file_name=good_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file_train = \"cnndm/fake_summary/train_hallucinated.csv\"\n",
    "\n",
    "fake_train = create_hallucinated_summaries(\n",
    "    df=datasets_train[\"train\"], \n",
    "    source_col=\"source\", \n",
    "    target_col=\"target\",\n",
    "    output_file_name = output_file_train\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Test and Validation Set Hallucinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file_test = \"cnndm/fake_summary/test_hallucinated.csv\"\n",
    "\n",
    "fake_test = create_hallucinated_summaries(\n",
    "    df=datasets_test_val[\"test\"], \n",
    "    source_col=\"source\", \n",
    "    target_col=\"target\",\n",
    "    output_file_name = output_file_test\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file_val = \"cnndm/fake_summary/val_hallucinated.csv\"\n",
    "\n",
    "fake_val = create_hallucinated_summaries(\n",
    "    df=datasets_test_val[\"valid\"], \n",
    "    source_col=\"source\",\n",
    "    target_col=\"target\",\n",
    "    output_file_name = output_file_val\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **The commented out code below was used to generate and save the fake summaries - since then I have added option to save the data directly via the function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 7000/7000 rows...\n",
      "Processing complete!\n"
     ]
    }
   ],
   "source": [
    "# fake_train = create_hallucinated_summaries(\n",
    "#     df=datasets_train[\"train\"], \n",
    "#     source_col=\"source\", \n",
    "#     target_col=\"target\"\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of hallucinated summaries saved to cnndm/fake_summary/train_hallucinated.csv\n"
     ]
    }
   ],
   "source": [
    "# df_hallucinated_train = pd.DataFrame(fake_train, columns=[\"fake_summary\"])\n",
    "\n",
    "# # Save to CSV\n",
    "# output_file_train = \"cnndm/fake_summary/train_hallucinated.csv\"\n",
    "# df_hallucinated_train.to_csv(output_file_train, index=False, encoding=\"utf-8\")\n",
    "\n",
    "# print(f\"List of hallucinated summaries saved to {output_file_train}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 1000/1000 rows...\n",
      "Processing complete!\n"
     ]
    }
   ],
   "source": [
    "# fake_test = create_hallucinated_summaries(\n",
    "#     df=datasets_test_val[\"test\"], \n",
    "#     source_col=\"source\", \n",
    "#     target_col=\"target\"\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of hallucinated summaries saved to cnndm/fake_summary/test_hallucinated.csv\n"
     ]
    }
   ],
   "source": [
    "# df_hallucinated_test = pd.DataFrame(fake_test, columns=[\"fake_summary\"])\n",
    "\n",
    "# # Save to CSV\n",
    "# output_file_test = \"cnndm/fake_summary/test_hallucinated.csv\"\n",
    "# df_hallucinated_test.to_csv(output_file_test, index=False, encoding=\"utf-8\")\n",
    "\n",
    "# print(f\"List of hallucinated summaries saved to {output_file_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 1000/1000 rows...\n",
      "Processing complete!\n"
     ]
    }
   ],
   "source": [
    "# fake_val = create_hallucinated_summaries(\n",
    "#     df=datasets_test_val[\"valid\"], \n",
    "#     source_col=\"source\", \n",
    "#     target_col=\"target\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of hallucinated summaries saved to cnndm/fake_summary/val_hallucinated.csv\n"
     ]
    }
   ],
   "source": [
    "# df_hallucinated_val = pd.DataFrame(fake_val, columns=[\"fake_summary\"])\n",
    "\n",
    "# # Save to CSV\n",
    "# output_file_val = \"cnndm/fake_summary/val_hallucinated.csv\"\n",
    "# df_hallucinated_val.to_csv(output_file_val, index=False, encoding=\"utf-8\")\n",
    "\n",
    "# print(f\"List of hallucinated summaries saved to {output_file_val}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adl_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
